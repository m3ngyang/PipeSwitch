0a1,2
> # torch/cuda/__init__.py
> 
462a465,493
> # PipeSwitch
> def allocate_shared_cache():
>     if _initialized:
>         torch._C._cuda_allocateSharedCache()
> 
> # PipeSwitch
> def send_shared_cache():
>     if _initialized:
>         torch._C._cuda_sendSharedCache()
> 
> # PipeSwitch
> def recv_shared_cache():
>     if _initialized:
>         torch._C._cuda_recvSharedCache()
> 
> # PipeSwitch
> def insert_shared_cache_for_parameter():
>     if _initialized:
>         torch._C._cuda_insertSharedCacheForParameter()
> 
> # PipeSwitch
> def insert_shared_cache_for_computation():
>     if _initialized:
>         torch._C._cuda_insertSharedCacheForComputation()
> 
> # PipeSwitch
> def clear_shared_cache():
>     if _initialized:
>         torch._C._cuda_clearSharedCache()
